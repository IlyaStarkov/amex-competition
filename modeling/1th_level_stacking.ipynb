{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjDfXFgUJMF3",
    "outputId": "a3c4a38c-b67a-4fb0-83be-c76d3b6d0b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Archive:  /content/drive/MyDrive/Colab Notebooks/AMEX-data/amex-data.zip\n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n",
      "  inflating: train_labels.csv        \n",
      "CPU times: user 2.82 s, sys: 472 ms, total: 3.29 s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "!unzip \"/content/drive/MyDrive/Colab Notebooks/AMEX-data/amex-data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d52k03r-G9wk",
    "outputId": "e824bd90-f725-4111-dbc5-4b25e7802e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vpb-f7ERKVSL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from colorama import Style, Fore\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKsFHn2BMWzV"
   },
   "outputs": [],
   "source": [
    "cat_features = ['B_30_0.0', 'B_30_1.0', 'B_30_2.0','B_38_1.0','B_38_2.0','B_38_3.0','B_38_4.0',\n",
    "            'B_38_5.0','B_38_6.0','B_38_7.0','D_114_0.0','D_114_1.0','D_116_0.0','D_116_1.0',\n",
    "            'D_117_-1.0','D_117_1.0','D_117_2.0','D_117_3.0','D_117_4.0','D_117_5.0','D_117_6.0',\n",
    "            'D_120_0.0','D_120_1.0','D_126_-1.0','D_126_0.0','D_126_1.0','D_63_CL','D_63_CO','D_63_CR',\n",
    "            'D_63_XL','D_63_XM','D_63_XZ','D_64_O','D_64_R','D_64_U','D_68_1.0',\n",
    "            'D_68_2.0','D_68_3.0','D_68_4.0','D_68_5.0','D_68_6.0','R_2_0.0','R_2_1.0','B_8_0.0',\n",
    "            'B_8_1.0','S_6_0.0','S_6_1.0','D_54_0.0','D_54_1.0','R_4_0.0','R_4_1.0','P_4_0.0',\n",
    "            'P_4_1.0','B_33_0.0','B_33_1.0','D_103_0.0','D_103_1.0','D_104_0.0','D_104_1.0',\n",
    "            'R_27_0.0','R_27_1.0','D_112_0.0','D_112_1.0','D_123_0.0','D_123_1.0','D_127_0.0',\n",
    "            'D_127_1.0','D_128_0.0','D_128_1.0','D_129_0.0','D_129_1.0','D_130_0.0','D_130_1.0',\n",
    "            'D_131_0.0','D_131_1.0','D_139_0.0','D_139_1.0','D_141_0.0','D_141_0.9','D_143_0.0',\n",
    "            'D_143_1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dq8qcRkMbAHk"
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSnGJRy7Maqm"
   },
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eovwotVXMdUu",
    "outputId": "46495b16-2769-47a9-c0d1-cc94ecdb9c4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2959.9750328063965"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', encoding = 'utf-8', sep = ';')\n",
    "labels = pd.read_csv(\"train_labels.csv\")\n",
    "df = df.merge(labels, on='customer_ID')\n",
    "sys.getsizeof(df)/2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olQ-9igFNgoG"
   },
   "outputs": [],
   "source": [
    "X = df.drop(['customer_ID', 'target', 'D_64_-1', 'D_68_0.0'], axis = 1)\n",
    "y = df['target']\n",
    "del df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zg8lyTH6tHNS"
   },
   "outputs": [],
   "source": [
    "class СustomForest:\n",
    "    def __init__(self, criterion='gini', max_depth=None, \n",
    "               random_state=None, min_samples_split=2, \n",
    "               min_samples_leaf=1, cat_features=[], verbose=False):\n",
    "    self.criterion = criterion\n",
    "    self.max_depth = max_depth\n",
    "    self.random_state = random_state\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "    self.cat_features = cat_features\n",
    "    self.verbose = verbose\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"СustomForest(criterion={0}, random_state={1}, verbose={2})\".format(\n",
    "          self.criterion, self.random_state, self.verbose\n",
    "          )\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_feature_classes(X):\n",
    "        columns = X.columns.to_list()\n",
    "        feature_classes = ['D', 'S', 'P', 'B', 'R']\n",
    "        res = []\n",
    "        for classf in feature_classes:\n",
    "            typef = []\n",
    "            for feature in columns:\n",
    "            if classf in feature:\n",
    "                typef.append(feature)\n",
    "        res.append(typef)\n",
    "        return dict(zip(feature_classes, res))\n",
    "\n",
    "    def __get_grouped_features(self, X):\n",
    "        columns = X.drop(self.cat_features+['S_2'], axis=1).columns.to_list()\n",
    "        res = []\n",
    "        for feature in columns:\n",
    "            classf, number, stat = feature.split('_')[0], feature.split('_')[1], feature.split('_')[2]\n",
    "            res.append(\"_\".join([classf, stat]))\n",
    "        grouped_features = list(set(res))\n",
    "        res = []\n",
    "        for grouped in grouped_features:\n",
    "            typef = []\n",
    "            classf, stat = grouped.split('_')[0], grouped.split('_')[1]\n",
    "            for feature in columns:\n",
    "                if (classf in feature) and (stat in feature):\n",
    "                    typef.append(feature)\n",
    "            res.append(typef)\n",
    "        return dict(zip(grouped_features, res))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        trees = []\n",
    "\n",
    "        grouped_features = self.__get_grouped_features(X)\n",
    "        feature_classes = self.__get_feature_classes(X)\n",
    "\n",
    "        grouped_features.update(feature_classes)\n",
    "        grouped_features.update({'cat_fwatures': self.cat_features})\n",
    "\n",
    "        for key, val in grouped_features.items():\n",
    "            if self.verbose:\n",
    "                print(\"building tree on {0}\".format(key))\n",
    "            tree = DecisionTreeClassifier(criterion=self.criterion, max_depth=self.max_depth, \n",
    "                                          random_state=self.random_state, \n",
    "                                          min_samples_split=self.min_samples_split, \n",
    "                                          min_samples_leaf=self.min_samples_leaf)\n",
    "            tree.fit(X[val], y)\n",
    "            trees.append(tree)\n",
    "        self.fitted_trees = dict(zip(grouped_features.keys(), trees))\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba_0, proba_1 = [], []\n",
    "        grouped_features = self.__get_grouped_features(X)\n",
    "        feature_classes = self.__get_feature_classes(X)\n",
    "        grouped_features.update(feature_classes)\n",
    "        grouped_features.update({'cat_fwatures': self.cat_features})\n",
    "        for key, tree in self.fitted_trees.items():\n",
    "            proba_0.append(tree.predict_proba(X[grouped_features.get(key)])[:, 0])\n",
    "            proba_1.append(tree.predict_proba(X[grouped_features.get(key)])[:, 1])\n",
    "        proba_0 = np.array(proba_0).mean(axis=0)\n",
    "        proba_1 = np.array(proba_1).mean(axis=0)\n",
    "        return np.vstack((proba_0, proba_1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPFZmANbCMFE"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "forest1 = СustomForest(criterion='gini', \n",
    "                       cat_features=cat_features, \n",
    "                       verbose=True, \n",
    "                       random_state=13)\n",
    "\n",
    "forest2 = СustomForest(criterion='entropy', \n",
    "                       cat_features=cat_features, \n",
    "                       verbose=True, \n",
    "                       random_state=21)\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators = 50, \n",
    "                              criterion='entropy', \n",
    "                              max_features='sqrt', \n",
    "                              min_samples_leaf=2, \n",
    "                              verbose=5, \n",
    "                              random_state=34,\n",
    "                              n_jobs=-1)\n",
    "rfc2 = RandomForestClassifier(n_estimators = 100, \n",
    "                              criterion='gini', \n",
    "                              max_features='log2', \n",
    "                              min_samples_leaf=4, \n",
    "                              verbose=5, \n",
    "                              random_state=55,\n",
    "                              n_jobs=-1)\n",
    "rfc3 = RandomForestClassifier(n_estimators = 150, \n",
    "                              criterion='entropy', \n",
    "                              max_features='sqrt', \n",
    "                              min_samples_leaf=8,\n",
    "                              verbose=5, \n",
    "                              random_state=89,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "rfc4 = RandomForestClassifier(n_estimators = 400, \n",
    "                              criterion='gini', \n",
    "                              max_features='log2', \n",
    "                              min_samples_leaf=16,\n",
    "                              verbose=5, \n",
    "                              random_state=144,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "lr1 = LogisticRegression(solver='sag', \n",
    "                         penalty='l2', \n",
    "                         C=7, \n",
    "                         random_state=233, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "lr2 = LogisticRegression(solver='sag', \n",
    "                         penalty='l2', \n",
    "                         C=1, \n",
    "                         random_state=377, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "models = [gnb, rfc1, rfc2, rfc3, rfc4, lr1, lr2, forest1, forest2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8jOdww2zCMJz",
    "outputId": "27e63df0-2d6b-44e9-8480-d7d3f6cbe37c"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1th model fitting. Model: LogisticRegression(C=7, n_jobs=-1, random_state=233, solver='sag')\u001b[0m\n",
      "\u001b[34m########## Fold 1 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 2 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 3 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 4 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 5 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m############################ \n",
      "\u001b[0m\n",
      "\u001b[1m2th model fitting. Model: LogisticRegression(C=1, n_jobs=-1, random_state=377, solver='sag')\u001b[0m\n",
      "\u001b[34m########## Fold 1 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 2 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 3 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 4 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 5 ##########\u001b[0m\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict for test on current fold...\n",
      "\u001b[34m############################ \n",
      "\u001b[0m\n",
      "\u001b[1m3th model fitting. Model: СustomForest(criterion=gini, random_state=13, verbose=True)\u001b[0m\n",
      "\u001b[34m########## Fold 1 ##########\u001b[0m\n",
      "building tree on R_std\n",
      "building tree on R_last\n",
      "building tree on P_std\n",
      "building tree on P_max\n",
      "building tree on S_mean\n",
      "building tree on P_first\n",
      "building tree on B_max\n",
      "building tree on D_std\n",
      "building tree on D_last\n",
      "building tree on D_min\n",
      "building tree on B_first\n",
      "building tree on S_min\n",
      "building tree on S_max\n",
      "building tree on B_min\n",
      "building tree on P_min\n",
      "building tree on S_last\n",
      "building tree on R_min\n",
      "building tree on R_first\n",
      "building tree on D_first\n",
      "building tree on D_mean\n",
      "building tree on B_mean\n",
      "building tree on R_mean\n",
      "building tree on R_max\n",
      "building tree on B_last\n",
      "building tree on P_mean\n",
      "building tree on S_first\n",
      "building tree on B_std\n",
      "building tree on P_last\n",
      "building tree on S_std\n",
      "building tree on D_max\n",
      "building tree on D\n",
      "building tree on S\n",
      "building tree on P\n",
      "building tree on B\n",
      "building tree on R\n",
      "building tree on cat_fwatures\n",
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 2 ##########\u001b[0m\n",
      "building tree on R_std\n",
      "building tree on R_last\n",
      "building tree on P_std\n",
      "building tree on P_max\n",
      "building tree on S_mean\n",
      "building tree on P_first\n",
      "building tree on B_max\n",
      "building tree on D_std\n",
      "building tree on D_last\n",
      "building tree on D_min\n",
      "building tree on B_first\n",
      "building tree on S_min\n",
      "building tree on S_max\n",
      "building tree on B_min\n",
      "building tree on P_min\n",
      "building tree on S_last\n",
      "building tree on R_min\n",
      "building tree on R_first\n",
      "building tree on D_first\n",
      "building tree on D_mean\n",
      "building tree on B_mean\n",
      "building tree on R_mean\n",
      "building tree on R_max\n",
      "building tree on B_last\n",
      "building tree on P_mean\n",
      "building tree on S_first\n",
      "building tree on B_std\n",
      "building tree on P_last\n",
      "building tree on S_std\n",
      "building tree on D_max\n",
      "building tree on D\n",
      "building tree on S\n",
      "building tree on P\n",
      "building tree on B\n",
      "building tree on R\n",
      "building tree on cat_fwatures\n",
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 3 ##########\u001b[0m\n",
      "building tree on R_std\n",
      "building tree on R_last\n",
      "building tree on P_std\n",
      "building tree on P_max\n",
      "building tree on S_mean\n",
      "building tree on P_first\n",
      "building tree on B_max\n",
      "building tree on D_std\n",
      "building tree on D_last\n",
      "building tree on D_min\n",
      "building tree on B_first\n",
      "building tree on S_min\n",
      "building tree on S_max\n",
      "building tree on B_min\n",
      "building tree on P_min\n",
      "building tree on S_last\n",
      "building tree on R_min\n",
      "building tree on R_first\n",
      "building tree on D_first\n",
      "building tree on D_mean\n",
      "building tree on B_mean\n",
      "building tree on R_mean\n",
      "building tree on R_max\n",
      "building tree on B_last\n",
      "building tree on P_mean\n",
      "building tree on S_first\n",
      "building tree on B_std\n",
      "building tree on P_last\n",
      "building tree on S_std\n",
      "building tree on D_max\n",
      "building tree on D\n",
      "building tree on S\n",
      "building tree on P\n",
      "building tree on B\n",
      "building tree on R\n",
      "building tree on cat_fwatures\n",
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 4 ##########\u001b[0m\n",
      "building tree on R_std\n",
      "building tree on R_last\n",
      "building tree on P_std\n",
      "building tree on P_max\n",
      "building tree on S_mean\n",
      "building tree on P_first\n",
      "building tree on B_max\n",
      "building tree on D_std\n",
      "building tree on D_last\n",
      "building tree on D_min\n",
      "building tree on B_first\n",
      "building tree on S_min\n",
      "building tree on S_max\n",
      "building tree on B_min\n",
      "building tree on P_min\n",
      "building tree on S_last\n",
      "building tree on R_min\n",
      "building tree on R_first\n",
      "building tree on D_first\n",
      "building tree on D_mean\n",
      "building tree on B_mean\n",
      "building tree on R_mean\n",
      "building tree on R_max\n",
      "building tree on B_last\n",
      "building tree on P_mean\n",
      "building tree on S_first\n",
      "building tree on B_std\n",
      "building tree on P_last\n",
      "building tree on S_std\n",
      "building tree on D_max\n",
      "building tree on D\n",
      "building tree on S\n",
      "building tree on P\n",
      "building tree on B\n",
      "building tree on R\n",
      "building tree on cat_fwatures\n",
      "predict for test on current fold...\n",
      "\u001b[34m########## Fold 5 ##########\u001b[0m\n",
      "building tree on R_std\n",
      "building tree on R_last\n",
      "building tree on P_std\n",
      "building tree on P_max\n",
      "building tree on S_mean\n",
      "building tree on P_first\n",
      "building tree on B_max\n",
      "building tree on D_std\n",
      "building tree on D_last\n",
      "building tree on D_min\n",
      "building tree on B_first\n",
      "building tree on S_min\n",
      "building tree on S_max\n",
      "building tree on B_min\n",
      "building tree on P_min\n",
      "building tree on S_last\n",
      "building tree on R_min\n",
      "building tree on R_first\n",
      "building tree on D_first\n",
      "building tree on D_mean\n",
      "building tree on B_mean\n",
      "building tree on R_mean\n",
      "building tree on R_max\n",
      "building tree on B_last\n",
      "building tree on P_mean\n",
      "building tree on S_first\n",
      "building tree on B_std\n",
      "building tree on P_last\n",
      "building tree on S_std\n",
      "building tree on D_max\n",
      "building tree on D\n",
      "building tree on S\n",
      "building tree on P\n",
      "building tree on B\n",
      "building tree on R\n",
      "building tree on cat_fwatures\n",
      "predict for test on current fold...\n",
      "\u001b[34m############################ \n",
      "\u001b[0m\n",
      "\u001b[1m4th model fitting. Model: СustomForest(criterion=entropy, random_state=21, verbose=True)\u001b[0m\n",
      "\u001b[34m########## Fold 1 ##########\u001b[0m\n",
      "building tree on R_std\n",
      "building tree on R_last\n",
      "building tree on P_std\n",
      "building tree on P_max\n",
      "building tree on S_mean\n",
      "building tree on P_first\n",
      "building tree on B_max\n",
      "building tree on D_std\n",
      "building tree on D_last\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b14b604f4532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3a8c21c5e221>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m                                     \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                                     min_samples_leaf=self.min_samples_leaf)\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m       \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#first layer of Stacking\n",
    "\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS)\n",
    "train_answers, test_answers = [], []\n",
    "for i, model in enumerate(models):\n",
    "    print(Style.BRIGHT+\"{0}th model fitting. Model: {1}\".format(i+1 ,model.__str__()) + Style.RESET_ALL)\n",
    "    answers = np.array([])\n",
    "    mean_test_answers = []\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print(Fore.BLUE + \"#\" * 10, f\"Fold {fold+1}\", \"#\" * 10 + Style.RESET_ALL)\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]\n",
    "        answers = np.hstack((answers, y_pred))\n",
    "\n",
    "        print('predict for test on current fold...')\n",
    "        test_chunks = pd.read_csv('test.csv', chunksize=20000, encoding = 'utf-8', sep = ';')\n",
    "        answers_fold = np.array([])\n",
    "        for test in test_chunks:\n",
    "            X_submit = test.drop(['customer_ID'], axis=1)\n",
    "            #X_submit = X_submit.to_numpy()\n",
    "            del test\n",
    "            _ = gc.collect()\n",
    "            y_pred_submit = model.predict_proba(X_submit)[:, 1]\n",
    "            del X_submit\n",
    "            _ = gc.collect()\n",
    "            answers_fold = np.hstack((answers_fold, y_pred_submit))\n",
    "        mean_test_answers.append(answers_fold)\n",
    "\n",
    "    test_answers.append(np.array(mean_test_answers).mean(axis=0))\n",
    "    train_answers.append(answers)\n",
    "    print(Fore.BLUE + \"#\" * 28, \"\\n\" + Style.RESET_ALL)\n",
    "train_answers = np.array(train_answers)\n",
    "test_answers = np.array(test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzCGSFWuk-OH"
   },
   "outputs": [],
   "source": [
    "train_answers = np.array(train_answers)\n",
    "test_answers = np.array(test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFDbxho0PAAl"
   },
   "outputs": [],
   "source": [
    "df_train_answ = pd.DataFrame({'gnb':train_answers[0], \n",
    "                              'rfc1': train_answers[1], \n",
    "                              'rfc2':train_answers[2], \n",
    "                              'rfc3':train_answers[3], \n",
    "                              'rfc4':train_answers[4], \n",
    "                              'lr1':train_answers[5], \n",
    "                              'lr2':train_answers[6], \n",
    "                              'forest1':train_answers[7], \n",
    "                              'forest2':train_answers[8]})\n",
    "df_train_answ.to_csv('train_answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tC6gvKuCPAIV"
   },
   "outputs": [],
   "source": [
    "df_test_answ = pd.DataFrame({'gnb':test_answers[0], \n",
    "                              'rfc1': test_answers[1], \n",
    "                              'rfc2':test_answers[2], \n",
    "                              'rfc3':test_answers[3], \n",
    "                              'rfc4':test_answers[4], \n",
    "                              'lr1':test_answers[5], \n",
    "                              'lr2':test_answers[6], \n",
    "                              'forest1':test_answers[7], \n",
    "                              'forest2':test_answers[8]})\n",
    "df_test_answ.to_csv('test_answers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "1th level stacking",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
